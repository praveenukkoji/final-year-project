{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Manikanta-Munnangi/CROP---Plant-Disease-Identification-Using-App/blob/master/Cnn-Code/Crop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTdhE8cZ_jJW"
   },
   "source": [
    "# `Mounting Dataset From Drive.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "RVCGkdwogKPt",
    "outputId": "b1f10b06-701a-48b4-e316-9e4c4be0f1b3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7t4rcphqCqK1"
   },
   "source": [
    "# `1.Import Libraries.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "o9XcN_vmg38P",
    "outputId": "45b0150a-b7ed-47da-bb9b-aa3dbc6eb513"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# Keras API\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,AveragePooling2D,BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EJ2OkcwC-xy"
   },
   "source": [
    "# `2.Load Data into Train and Test Variables.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3KoUJXj9ik2_"
   },
   "outputs": [],
   "source": [
    "# My data is in google drive.\n",
    "train_dir =\"drive/My Drive/train_set/\"\n",
    "test_dir=\"drive/My Drive/test_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPfOAeA8DZ9b"
   },
   "source": [
    "# `3.Function To count Images In Each Data Set.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGx5-TibjLMn"
   },
   "outputs": [],
   "source": [
    "# function to get count of images\n",
    "def get_files(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  count=0\n",
    "  for current_path,dirs,files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uE1cHgPijwx1",
    "outputId": "fd27c5f2-7705-4623-dffe-6b2a4f5888bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Classes\n",
      "0 Train images\n",
      "0 Test images\n"
     ]
    }
   ],
   "source": [
    "train_samples =get_files(train_dir)\n",
    "num_classes=len(glob.glob(train_dir+\"/*\"))\n",
    "test_samples=get_files(test_dir) # For testing i took only few samples from unseen data. we can evaluate using validation data which is part of train data.\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n",
    "print(test_samples,\"Test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-CTlyJ_usrY"
   },
   "outputs": [],
   "source": [
    "# Preprocessing data.\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   validation_split=0.2, # validation split 20%.\n",
    "                                   horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "H8NqDpMysS_K",
    "outputId": "6149ae50-427a-45a9-8840-4c4310880291"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'drive/My Drive/train_set/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m input_shape\u001b[38;5;241m=\u001b[39m(img_width,img_height,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test_generator\u001b[38;5;241m=\u001b[39mtest_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(test_dir,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                                                    target_size\u001b[38;5;241m=\u001b[39m(img_width,img_height),\n\u001b[1;32m     11\u001b[0m                                                    batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/Developer/Final Year Project/plant-disease-detection/venv/lib/python3.9/site-packages/keras/preprocessing/image.py:1469\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1387\u001b[0m                         directory,\n\u001b[1;32m   1388\u001b[0m                         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m                         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1401\u001b[0m                         keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1402\u001b[0m   \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m \n\u001b[1;32m   1404\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;124;03m          and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1469\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m      \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/Final Year Project/plant-disease-detection/venv/lib/python3.9/site-packages/keras/preprocessing/image.py:507\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    506\u001b[0m   classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 507\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    509\u001b[0m       classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/train_set/'"
     ]
    }
   ],
   "source": [
    "# set height and width and color of input image.\n",
    "img_width,img_height =256,256\n",
    "input_shape=(img_width,img_height,3)\n",
    "batch_size =32\n",
    "\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(img_width,img_height),\n",
    "                                                   batch_size=batch_size)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,\n",
    "                                                   target_size=(img_width,img_height),\n",
    "                                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "RMBDe-RLg1Na",
    "outputId": "79673a5a-8e7e-4ea9-b929-3edf8bb2c13d"
   },
   "outputs": [],
   "source": [
    "# The name of the 12 diseases.\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIffvBpe-y8N"
   },
   "source": [
    "# `4.CNN Parameter Building.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "02pX54IExHAI",
    "outputId": "4ff598a7-af76-440a-cc87-b0e7452c7644"
   },
   "outputs": [],
   "source": [
    "# CNN building.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))          \n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MR5A-tIKR8oY",
    "outputId": "0fa19935-b217-407b-eb8c-ba154e9da887"
   },
   "outputs": [],
   "source": [
    "model_layers = [ layer.name for layer in model.layers]\n",
    "print('layer name : ',model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "uEpegULD-jHG",
    "outputId": "58296226-2164-4eb1-f028-4001ee4426ff"
   },
   "outputs": [],
   "source": [
    "# Take one image to visualize it's changes after every layer\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img1 = image.load_img('/content/drive/My Drive/Train_d/Tomato___Early_blight/Tomato___Early_blight (10).JPG')\n",
    "plt.imshow(img1);\n",
    "\n",
    "#preprocess image\n",
    "img1 = image.load_img('/content/drive/My Drive/Train_d/Tomato___Early_blight/Tomato___Early_blight (10).JPG', target_size=(256, 256))\n",
    "img = image.img_to_array(img1)\n",
    "img = img/255\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "CCjt2wHNSC28",
    "outputId": "43730428-ef02-406b-af84-e2ec35ba8350"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualizing output after every layer.\n",
    "from keras.models import Model\n",
    "conv2d_1_output = Model(inputs=model.input, outputs=model.get_layer('conv2d_1').output)\n",
    "max_pooling2d_1_output = Model(inputs=model.input,outputs=model.get_layer('max_pooling2d_1').output)\n",
    "conv2d_2_output = Model(inputs=model.input,outputs=model.get_layer('conv2d_2').output)\n",
    "max_pooling2d_2_output = Model(inputs=model.input,outputs=model.get_layer('max_pooling2d_2').output)\n",
    "conv2d_3_output = Model(inputs=model.input,outputs=model.get_layer('conv2d_3').output)\n",
    "max_pooling2d_3_output = Model(inputs=model.input,outputs=model.get_layer('max_pooling2d_3').output)\n",
    "flatten_1_output = Model(inputs=model.input,outputs=model.get_layer('flatten_1').output)\n",
    "conv2d_1_features = conv2d_1_output.predict(img)\n",
    "max_pooling2d_1_features = max_pooling2d_1_output.predict(img)\n",
    "conv2d_2_features = conv2d_2_output.predict(img)\n",
    "max_pooling2d_2_features = max_pooling2d_2_output.predict(img)\n",
    "conv2d_3_features = conv2d_3_output.predict(img)\n",
    "max_pooling2d_3_features = max_pooling2d_3_output.predict(img)\n",
    "flatten_1_features = flatten_1_output.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rgxVYpLGS9d"
   },
   "source": [
    "# `5.Visualizing The Image After Every Layer.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "5Wu8JY_FbaHu",
    "outputId": "499b9dd4-04d0-4b9e-9e73-cc438e9a3bc6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_1_features[0, :, :, i], cmap='viridis') # Visualizing in color mode.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "EhD7gO5ieRX-",
    "outputId": "b5c10573-5fe8-4c1f-b3fa-62f411310a3f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(max_pooling2d_1_features[0, :, :, i], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "1YgyE3AdcAO2",
    "outputId": "b2bd6212-15f7-48dc-9a60-3c9d3520d665"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_2_features[0, :, :, i], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "mNhrHwPJeljn",
    "outputId": "34fa302f-447b-4429-8cfa-ebb5b9baa69b"
   },
   "outputs": [],
   "source": [
    "# we can also visualize in color mode.\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(max_pooling2d_2_features[0, :, :, i], cmap='viridis') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "7uzflC4McLst",
    "outputId": "6d01b4b0-4bb5-4c77-dcb7-132b0ce4e4c3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns =8 \n",
    "rows = 8\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_3_features[0, :, :, i], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "colab_type": "code",
    "id": "d1uo495ie2wq",
    "outputId": "a76683c3-3bd7-41a4-c5f1-46b04ea6ce85"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,14))\n",
    "columns = 8\n",
    "rows = 8\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(max_pooling2d_3_features[0, :, :, i],cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txZYUHCYAnbm"
   },
   "source": [
    "# `6.Training The Model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qv_ow-jPBDnQ",
    "outputId": "025f2774-dcd1-4766-e72b-dab193c678ac"
   },
   "outputs": [],
   "source": [
    "# validation data.\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "d1GPempn06uE",
    "outputId": "54026867-80aa-444c-d6eb-9a301580d352"
   },
   "outputs": [],
   "source": [
    "# Model building to get trained with parameters.\n",
    "opt=keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "train=model.fit_generator(train_generator,\n",
    "                          nb_epoch=15,\n",
    "                          steps_per_epoch=train_generator.samples // batch_size,\n",
    "                          validation_data=validation_generator,\n",
    "                          nb_val_samples= validation_generator.samples// batch_size,verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYpo1Sr5AXv-"
   },
   "source": [
    "# `7.Plot For Accuracy And Losses.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "O_SLJxPxvORf",
    "outputId": "7e46b139-966e-42c3-a245-21c6bd67be1d"
   },
   "outputs": [],
   "source": [
    "acc = train.history['acc']\n",
    "val_acc = train.history['val_acc']\n",
    "loss = train.history['loss']\n",
    "val_loss = train.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2qQ20VwUPvO"
   },
   "source": [
    "# `8. Evaluate model using unseen data.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "sWsPrcGkWBYC",
    "outputId": "69bb18e0-ded2-4db2-ff80-4e1c9b5fa4bd"
   },
   "outputs": [],
   "source": [
    "score,accuracy =model.evaluate(test_generator,verbose=1)\n",
    "print(\"Test score is {}\".format(score))\n",
    "print(\"Test accuracy is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYs8zwNeAJE-"
   },
   "source": [
    "# `9.Saving Model.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZuavjSmz6wb"
   },
   "outputs": [],
   "source": [
    "# Save entire model with optimizer, architecture, weights and training configuration.\n",
    "from keras.models import load_model\n",
    "model.save('crop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sF46Kp3JEEfT"
   },
   "outputs": [],
   "source": [
    "# Save model weights.\n",
    "from keras.models import load_model\n",
    "model.save_weights('crop_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "qooFmBja9sQn",
    "outputId": "8680285c-fff6-41ea-9460-ca0ac7e4d6ab"
   },
   "outputs": [],
   "source": [
    "# Get classes of model trained on\n",
    "classes = train_generator.class_indices \n",
    "classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwbrCZY8_41b"
   },
   "source": [
    "# `10.Load Model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFeWlgy_5oSy"
   },
   "outputs": [],
   "source": [
    "# Loading model and predict.\n",
    "from keras.models import load_model\n",
    "model=load_model('crop.h5')\n",
    "\n",
    "Classes = [\"Potato___Early_blight\",\"Potato___Late_blight\",\"Potato___healthy\",\"Tomato___Bacterial_spot\",\"Tomato___Early_blight\",\"Tomato___Late_blight\",\"Tomato___Leaf_Mold\",\"Tomato___Septoria_leaf_spot\",\"Tomato___Spider_mites Two-spotted_spider_mite\",\"Tomato___Target_Spot\",\"Tomato___Tomato_mosaic_virus\",\"Tomato___healthy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3w5ndzU_Qqi"
   },
   "source": [
    "# `11.Time For Predictions.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "7Crovs5tgVpx",
    "outputId": "685873d1-17e4-498c-af0e-a8414faca36a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pre-Processing test data same as train data.\n",
    "img_width=256\n",
    "img_height=256\n",
    "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def prepare(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    x = image.img_to_array(img)\n",
    "    x = x/255\n",
    "    return np.expand_dims(x, axis=0)\n",
    "    \n",
    "    \n",
    "result = model.predict_classes([prepare('/content/drive/My Drive/Test_d/Tomato_BacterialSpot/Tomato___Bacterial_spot (901).JPG')])\n",
    "disease=image.load_img('/content/drive/My Drive/Test_d/Tomato_BacterialSpot/Tomato___Bacterial_spot (901).JPG')\n",
    "plt.imshow(disease)\n",
    "print (Classes[int(result)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXsCoNhv8_oE"
   },
   "source": [
    "# `12.Convert Model To \"tflite format.\"`.\n",
    "- This conversion is done because to make our model interpertable with App.\n",
    "- tflite is tensorflowlite made for mobile versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "9oaFo9BH-Bgh",
    "outputId": "79d8260f-9431-458b-e40d-ee97add6559b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('crop.h5') \n",
    "tfmodel = converter.convert() \n",
    "open (\"output.tflite\" , \"wb\") .write(tfmodel)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Crop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
